---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "README-figures/",
  warnings = FALSE
)

#q()
#R
#devtools::install("~/repos/compboost")

devtools::load_all(quiet = TRUE)
library(ggplot2, quietly = TRUE)
library(dplyr, quietly = TRUE)

### Need to put this directly in compboost:
predict.compboostExtract = function(object, newdata) {
  feats = names(object)
  feats = feats[feats != "offset"]
  out = lapply(feats, function(ft) {
    if (! ft %in% names(newdata)) {
      warning("New data should contain all features used for building the model! Feature ", ft, " is missing.")
      return(NULL)
    } else {
      eff = object[[ft]]$predict(newdata[[ft]])
      pe = eff$linear + eff$nonlinear
      return(list(pe = pe, effects = eff, src = newdata[[ft]]))
    }
  })
  names(out) = feats
  pred = rowSums(do.call(cbind, lapply(out, function(x) x$pe))) + object$offset
  return(list(pred = pred, pe = out, offset = object$offset))
}

plotCategorical = function(feats, pe) {
  plt_dat = do.call(rbind, lapply(feats, function(feat) {
    if (! any(grepl(feat, names(pe))))
      stop("Feature ", feat, " not in partial effects data.")
    fidx = grep(feat, names(pe))
    plt_data = data.frame(cat = rownames(pe[[fidx]]), est = pe[[fidx]], feature = feat)
  }))
  ggplot(data = plt_dat, aes(x = cat, y = est)) +
    geom_boxplot() +
    ylab("Contribution to prediction") +
    xlab("") +
    labs(color = "") +
    theme(legend.position = "bottom") +
    facet_wrap(. ~ feature, ncol = 3, scales = "free")
}

plotNumeric = function(feats, pe) {
  plt_dat = do.call(rbind, lapply(feats, function(feat) {
    if (! feat %in% names(pe$pe))
      stop("Feature ", feat, " not in partial effects data.")
    p = pe$pe[[feat]]
    data.frame(x = p$src, pe = p$pe, linear = p$effects$linear,
      nonlinear = p$effects$nonlinear, feature = feat)
  }))
  ggplot(data = plt_dat, aes(x = x)) +
    geom_line(aes(y = linear, color = "Linear part"), alpha = 0.6, linetype = "dashed") +
    geom_line(aes(y = nonlinear, color = "Nonlinear part"), alpha = 0.6, linetype = "dashed") +
    geom_line(aes(y = pe, color = "Partial effect"), size = 1.3) +
    geom_rug() +
    ylab("Contribution to prediction") +
    xlab("") +
    labs(color = "") +
    theme(legend.position = "bottom") +
    facet_wrap(. ~ feature, ncol = 3, scales = "free")
}

predictTensor = function(dat, dato, coef, tnames, n_knots, degree) {
  xo1 = dat[[tnames[1]]]
  xo2 = dat[[tnames[2]]]

  x1 = dat[[tnames[1]]]
  x2 = dat[[tnames[2]]]

  knots1 = cpsp::createKnots(values = xo1, n_knots = n_knots, degree = degree)
  basis1 = cpsp::createSplineBasis(values = x1, degree = degree, knots = knots1)

  knots2 = cpsp::createKnots(values = xo2, n_knots = n_knots, degree = degree)
  basis2 = cpsp::createSplineBasis(values = x2, degree = degree, knots = knots2)

  tensor = cpsp::rowWiseTensor(basis1, basis2)
  return(tensor %*% coef)
}
```

# autocompboost

### Use case

```{r}
# Use adult task from OpenML:
task = tsk("oml", task_id = 7592)

# Remove rows with missings:
task$filter(which(complete.cases(task$data())))

# Train compboost learner:
set.seed(31415)
cboost = lrn("classif.compboost", predict_type = "prob", show_output = TRUE,
  learning_rate = 0.01, add_deeper_interactions = TRUE,
  stop_epsylon_for_break = 0, stop_patience = 3L, df = 4)
cboost$train(task)
```

### Information about the stages:

```{r, fig.height=2}
## How much risk was explained by which stage:
rstages = cboost$getRiskStages()
knitr::kable(rstages)

rstages = rstages[-1, ]
rstages$stage = factor(rstages$stage, levels = rstages$stage)
ggplot(rstages, aes(x = "", y = percentage, fill = stage)) +
  geom_bar(stat = "identity") +
  theme(legend.position = "bottom") +
  coord_flip() +
  scale_y_reverse() +
  xlab("") +
  ylab("") +
  ggtitle("Explained risk per stage") +
  labs(fill = "") +
  ggsci::scale_fill_uchicago()
```

### Univariate model

#### Feature importance

```{r}
## Feature importance
cboost$model$univariate$calculateFeatureImportance()
vip = cboost$model$univariate$calculateFeatureImportance(aggregate_bl_by_feat = TRUE)
cboost$model$univariate$plotFeatureImportance(aggregate_bl_by_feat = TRUE)
```

#### Partial effects

```{r, fig.height=3}
coefs = cboost$model$univariate$getEstimatedCoef()
offset = coefs$offset

# numeric
extract = cboost$model$univariate$extractComponents()
pe_numeric = predict(extract, newdata = task$data())

# categorical
pe_cat = coefs[grepl("Categorical", vapply(coefs, function(cf) {
    atr = attr(cf, "blclass")
    if (is.null(atr))
      return("Offset")
    else
      return(atr)
  }, character(1L)))]

# Visualize top vars:

# Visualize categorical features:
plotCategorical(c("marital.status", "relationship", "occupation"), pe_cat) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Visualize numerical features:
plotNumeric(c("education.num", "capital.gain", "age"), pe_numeric) +
  ggsci::scale_color_uchicago()
```

### Pairwise interactions


#### Feature importance

```{r}
vip_int = cboost$model$interactions$calculateFeatureImportance()
top_interaction = vip_int$baselearner[1]
cboost$model$interactions$plotFeatureImportance()
```

#### Visualize interaction `r top_interaction`

```{r}
coefs_int = cboost$model$interactions$getEstimatedCoef()[[top_interaction]]

dat0 = cboost$model$univariate$data

dat = expand.grid(age = seq(min(dat0$age), max(dat0$age), length.out = 100),
  capital.gain = seq(min(dat0$capital.gain), max(dat0$capital.gain), length.out = 100))

n_knots = 8
degree = 3

dat$y = predictTensor(dat, dat0, coefs_int, c("age", "capital.gain"), n_knots, degree)
ggplot() +
  geom_contour_filled(data = dat, aes(x = age, y = capital.gain, z = y), bins = 15) +
  geom_rug(data = dat0, aes(x = age, y = capital.gain))
```

#### Prediction decomposition



```{r, fig.height=3}
# "new observation"
newdata = task$data()[1234,]
newdata$class = NULL
knitr::kable(t(newdata))

p_uni = cboost$model$univariate$predictIndividual(newdata)
p_int = cboost$model$interactions$predictIndividual(newdata)
p_int$offset = NULL

df_new = newdata
df_new$residuals = 0
tsk_new = TaskRegr$new(id = "residuals", backend = df_new, target = "residuals")
p_trees = predict.residualBooster(cboost$model$deeper_interactions, tsk_new)



p = c(p_uni, p_int, other = p_trees)

df_plt = data.frame(blearner = names(p), value = unlist(p),
  stage = rep(c("Univariate", "Pairwise interactions", "Deep trees"), times = c(length(p_uni), length(p_int), 1)))
df_plt$blearner = factor(df_plt$blearner, levels = rev(df_plt$blearner))
df_plt$stage = factor(df_plt$stage, levels = c("Univariate", "Pairwise interactions", "Deep trees"))
df_plt$bl_num = rev(seq_along(df_plt$blearner))

fnames = c("offset", "other", task$feature_names)
fidx = t(do.call(rbind, lapply(fnames, function(feat) grepl(feat, df_plt$blearner))))

flab = character(nrow(fidx))
for (i in seq_len(nrow(fidx))) {
  feats = fnames[fidx[i, ]]

  if (length(feats) > 1) {
    df_char = data.frame(f = feats, n = nchar(feats))
    df_char = df_char[order(df_char$n, decreasing = TRUE), ]
    df_char$count = sapply(df_char$f, function(fn) sum(grepl(fn, df_char$f)))
    feats = df_char$f[df_char$count == 1]
  }
  feats = vapply(feats, function(f) {
    if (f %in% c("other", "offset")) return(f)

    fval = newdata[[f]]
    if (is.numeric(fval))
      return(paste0(f, " (", round(fval, 2), ")"))
    else
      return(paste0(f, " (", fval, ")"))
  }, character(1L))

  if (length(feats) == 2)
    flab[i] = paste0("Interaction: ", paste(feats, collapse = ", "))
  else
    flab[i] = feats
}
flab[flab == "other"] = "Deep trees"
df_plt$feat = flab
df_plt0 = df_plt %>%
  group_by(feat) %>%
  summarize(value = sum(value), stage = stage[1]) %>%
  ungroup() %>%
  arrange(desc(stage)) %>%
  mutate(bl_num = seq_along(value))

pred = sum(df_plt0$value)
prob = 1 / (1 + exp(-pred))
plabel = ifelse(prob > 0.5, task$positive, task$negative)

title = "Prediction"
subtitle = paste0("Score: ", round(pred, 2), " Probability: ", round(prob, 2), " Predicted label: ", plabel)

ggplot(df_plt0, aes(x = value, y = bl_num, color = stage, fill = stage)) +
  geom_vline(xintercept = 0, color = "dark grey", alpha = 0.6) +
  geom_segment(aes(xend = 0, yend = bl_num)) +
  geom_point() +
  ylab("") +
  xlab("Contribution to predicted value") +
  labs(color = "", fill = "") +
  ggsci::scale_fill_uchicago() +
  ggsci::scale_color_uchicago() +
  #scale_y_reverse() +
  scale_y_continuous(labels = df_plt0$feat, breaks = df_plt0$bl_num) +
  theme_minimal() +
  ggtitle(title, subtitle)

```
